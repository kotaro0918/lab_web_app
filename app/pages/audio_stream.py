"""
Streamlit UI for realâ€‘time voice chat with Gemini LiveÂ API
=========================================================
â€¢ Click **Start Conversation** to open your mic and begin talking.
â€¢ The assistantâ€™s responses will be spoken back and simultaneously shown
  as text below.
â€¢ Click **Stop Conversation** to end the live session and release the mic.

> âš ï¸Â Run this script locally. Most browsers/hosted services do not allow
> lowâ€‘level microphone access from Python.
> Ensure GOOGLE_API_KEY (or GEMINI_API_KEY) is set in credential/.env.

### Key improvements vs. Google sample
1. **No more truncated responses** â€“ audio frames are *never* dropped and
   the playback queue is not cleared midâ€‘turn.
2. **Backâ€‘pressure aware** â€“ await queue.put() prevents overflow.
3. **Turnâ€‘end sentinel (__END__)** â€“ precise detection of Geminiâ€™s turn
   completion; allows gapless playback without arbitrary sleeps.
4. **PythonÂ 3.10 support** via taskgroup / exceptiongroup backâ€‘ports.
"""

from __future__ import annotations
import asyncio
import sys
import threading
from queue import Queue, Empty
from typing import Optional

import numpy as np
import sounddevice as sd
import streamlit as st
from google import genai

# Python 3.10 å¯¾å¿œ: TaskGroup äº’æ›
if sys.version_info < (3, 11):
    import taskgroup  # pip install taskgroup
    import exceptiongroup  # pip install exceptiongroup

    asyncio.TaskGroup = taskgroup.TaskGroup  # type: ignore[attr-defined]
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup  # type: ignore[attr-defined]

# Constants
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHANNELS = 1
CHUNK_SIZE = 4096
MODEL = "gemini-2.5-flash-exp-native-audio-thinking-dialog"
CONFIG = {
    "response_modalities": ["AUDIO"],
    "system_instruction": "You are a Japanese helpful assistant and answer in a friendly tone.answer in Japanese. and shortly.",
}

client = genai.Client()


# â˜…â˜…â˜… è¿½åŠ : ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ã®ãƒã‚§ãƒƒã‚¯ â˜…â˜…â˜…
def check_audio_devices():
    """åˆ©ç”¨å¯èƒ½ãªå…¥å‡ºåŠ›ãƒ‡ãƒã‚¤ã‚¹ã‚’ç¢ºèªã—ã€ãªã‘ã‚Œã°ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹"""
    try:
        sd.check_input_settings(samplerate=SEND_SAMPLE_RATE, channels=CHANNELS)
        print("[âœ…] Default input device is OK.")
    except Exception as e:
        print(f"[âŒ] No suitable input device found: {e}")
        raise RuntimeError("ãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚") from e

    try:
        sd.check_output_settings(samplerate=RECEIVE_SAMPLE_RATE, channels=CHANNELS)
        print("[âœ…] Default output device is OK.")
    except Exception as e:
        print(f"[âŒ] No suitable output device found: {e}")
        raise RuntimeError(
            "ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã¾ãŸã¯ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        ) from e


class AudioLoop:
    END_TOKEN: bytes = b"__END__"

    def __init__(self, *, text_queue: Optional[Queue] = None):
        self.text_queue = text_queue
        self.session: Optional[genai.aio.LiveSession] = None
        self.is_playing = asyncio.Event()
        # â˜… ä¿®æ­£: out_queueã¯é€šå¸¸ã®ã‚­ãƒ¥ãƒ¼ã§OK
        self.out_queue: Queue[dict] = Queue(maxsize=1000)
        self.audio_in_queue: asyncio.Queue[bytes] = asyncio.Queue(maxsize=100)
        self.last_played_frames: list[bytes] = []
        self._stop_event = asyncio.Event()
        self._tasks: list[asyncio.Task] = []

    # â˜…â˜…â˜… ä¿®æ­£ç‚¹: listen_audioã‚’ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹å¼ã«å¤‰æ›´ â˜…â˜…â˜…
    def _audio_callback(self, indata: np.ndarray, frames: int, time, status) -> None:
        """sounddeviceã‹ã‚‰åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å‘¼ã³å‡ºã•ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if status:
            print(f"[âš ï¸] Audio callback status: {status}")

        audio_bytes = indata.tobytes()

        # å†ç”Ÿä¸­ã®ã‚¨ã‚³ãƒ¼ã‚„ç„¡éŸ³ã‚’é€ä¿¡ã—ãªã„
        if self.is_playing.is_set() or audio_bytes in self.last_played_frames:
            return

        try:
            # out_queueã¯é€šå¸¸ã‚­ãƒ¥ãƒ¼ãªã®ã§put_nowaitã§OK
            self.out_queue.put_nowait(
                {
                    "data": audio_bytes,
                    # â˜…â˜…â˜… ä¿®æ­£: APIãŒè¦æ±‚ã™ã‚‹MIMEã‚¿ã‚¤ãƒ—å½¢å¼ã«å¤‰æ›´ â˜…â˜…â˜…
                    "mime_type": f"audio/pcm;rate={SEND_SAMPLE_RATE}",
                }
            )
            print(f"[ğŸ™] Captured and queued audio: {len(audio_bytes)} bytes")
        except asyncio.QueueFull:
            print("[âš ï¸] out_queue is full, dropping frame.")

    async def listen_audio(self) -> None:
        """ãƒã‚¤ã‚¯ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’é–‹å§‹ã—ã€åœæ­¢ã‚¤ãƒ™ãƒ³ãƒˆã‚’å¾…ã¤"""
        print("[ğŸ™] Starting microphone capture using callback...")
        loop = asyncio.get_running_loop()

        # InputStreamã‚’ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§é–‹ã
        stream = sd.InputStream(
            samplerate=SEND_SAMPLE_RATE,
            channels=CHANNELS,
            dtype="int16",
            blocksize=CHUNK_SIZE,
            # loop.call_soon_threadsafeã‚’ä½¿ã£ã¦ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ç™»éŒ²
            callback=lambda *args: loop.call_soon_threadsafe(
                self._audio_callback, *args
            ),
        )
        with stream:
            # ã‚¹ãƒˆãƒƒãƒ—ã‚¤ãƒ™ãƒ³ãƒˆãŒç™ºç”Ÿã™ã‚‹ã¾ã§å¾…æ©Ÿ
            await self._stop_event.wait()
        print("[ğŸ™] Microphone capture stopped.")

    async def send_realtime(self) -> None:
        print("[ğŸš€] Starting realtime send loop...")
        loop = asyncio.get_running_loop()
        while not self._stop_event.is_set():
            try:
                # é€šå¸¸ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å–å¾—ã™ã‚‹ãŸã‚ã«run_in_executorã‚’ä½¿ç”¨
                msg = await loop.run_in_executor(None, self.out_queue.get, True, 0.1)
                print(f"[ğŸš€] Sending frame: {len(msg['data'])} bytes")
                if self.session:
                    await self.session.send_realtime_input(audio=msg)
            except Empty:
                await asyncio.sleep(0.01)  # ã‚­ãƒ¥ãƒ¼ãŒç©ºãªã‚‰å°‘ã—å¾…ã¤

    async def receive_audio(self) -> None:
        print("[ğŸ“¥] Starting receive loop...")
        while not self._stop_event.is_set():
            try:
                async for resp in self.session.receive():
                    if self._stop_event.is_set():
                        break

                    # â˜…â˜…â˜… ä¿®æ­£: å¿œç­”ã®æ§‹é€ ã‚’åˆ¤åˆ¥ã—ã¦å‡¦ç†ã™ã‚‹ â˜…â˜…â˜…
                    if hasattr(resp, "parts"):
                        # ãƒãƒ«ãƒãƒ‘ãƒ¼ãƒˆå¿œç­”ã®å ´åˆ
                        for part in resp.parts:
                            if part.audio and part.audio.data:
                                print(
                                    f"[ğŸ“¥] Received audio frame: {len(part.audio.data)} bytes"
                                )
                                await self.audio_in_queue.put(part.audio.data)
                            if part.text:
                                print(f"[ğŸ“] Received text: {part.text}")
                                if self.text_queue:
                                    self.text_queue.put_nowait(part.text)
                    else:
                        # ã‚·ãƒ³ãƒ—ãƒ«ãªå¿œç­”ã®å ´åˆ
                        if resp.data:
                            print(f"[ğŸ“¥] Received audio frame: {len(resp.data)} bytes")
                            await self.audio_in_queue.put(resp.data)
                        if resp.text:
                            print(f"[ğŸ“] Received text: {resp.text}")
                            if self.text_queue:
                                self.text_queue.put_nowait(resp.text)

                # ã‚¿ãƒ¼ãƒ³ãŒæ­£å¸¸ã«çµ‚äº†ã—ãŸå ´åˆ
                print("[ğŸ“¥] End of Gemini turn")
                await self.audio_in_queue.put(self.END_TOKEN)

            except asyncio.CancelledError:
                # ã‚¿ã‚¹ã‚¯ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚ŒãŸå ´åˆã¯é™ã‹ã«çµ‚äº†
                break
            except Exception as e:
                # äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦ãƒ­ã‚°ã«å‡ºåŠ›
                print(f"[âŒ] FATAL ERROR in receive_audio: {e}")
                # ã‚¨ãƒ©ãƒ¼ã‚’å†é€å‡ºã—ã¦TaskGroupã«é€šçŸ¥
                raise

    async def play_audio(self) -> None:
        print("[ğŸ”Š] Starting audio playback...")
        try:
            with sd.OutputStream(
                samplerate=RECEIVE_SAMPLE_RATE, channels=CHANNELS, dtype="int16"
            ) as stream:
                while self.audio_in_queue.qsize() < 2 and not self._stop_event.is_set():
                    await asyncio.sleep(0.01)
                while not self._stop_event.is_set():
                    frame = await self.audio_in_queue.get()
                    if frame == self.END_TOKEN:
                        print("[ğŸ”Š] Received END_TOKEN â€” turn complete")
                        await asyncio.sleep(0.3)
                        self.is_playing.clear()
                        continue
                    self.is_playing.set()
                    self.last_played_frames.append(frame)
                    if len(self.last_played_frames) > 400:
                        self.last_played_frames.pop(0)
                    print(f"[ğŸ”Š] Playing audio frame: {len(frame)} bytes")
                    np_frame = np.frombuffer(frame, dtype="int16")
                    stream.write(np_frame)
        # â˜…â˜…â˜… è¿½åŠ : play_audioå†…ã®ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦ãƒ­ã‚°ã«å‡ºåŠ› â˜…â˜…â˜…
        except Exception as e:
            print(f"[âŒ] FATAL ERROR in play_audio: {e}")
            # ã‚¨ãƒ©ãƒ¼ã‚’å†é€å‡ºã—ã¦TaskGroupã«é€šçŸ¥
            raise

    async def run(self) -> None:
        print("[âš™ï¸] Connecting to Gemini live session...")
        async with client.aio.live.connect(model=MODEL, config=CONFIG) as session:
            self.session = session
            print("[âœ…] Connected to Gemini")
            async with asyncio.TaskGroup() as tg:
                self._tasks.extend(
                    [
                        tg.create_task(self.listen_audio()),
                        tg.create_task(self.send_realtime()),
                        tg.create_task(self.receive_audio()),
                        tg.create_task(self.play_audio()),
                    ]
                )

    def stop(self) -> None:
        print("[ğŸ›‘] Stopping audio loop")
        self._stop_event.set()
        for t in self._tasks:
            t.cancel()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Gemini Voice Chat", page_icon="ğŸ—£ï¸")
st.title("ğŸ—£ï¸ Gemini Voice Chat Demo")

if "app_state" not in st.session_state:
    st.session_state.app_state = "stopped"
    st.session_state.loop_thread: Optional[threading.Thread] = None
    st.session_state.audio_loop: Optional[AudioLoop] = None
    st.session_state.text_buffer = ""
    st.session_state.queue: Queue[str] = Queue()

status_placeholder = st.empty()
text_placeholder = st.empty()


def _start_chat() -> None:
    if st.session_state.app_state == "running":
        return

    # â˜…â˜…â˜… è¿½åŠ : ãƒãƒ£ãƒƒãƒˆé–‹å§‹å‰ã«ãƒ‡ãƒã‚¤ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯ â˜…â˜…â˜…
    try:
        check_audio_devices()
    except RuntimeError as e:
        st.error(str(e))
        return

    loop = AudioLoop(text_queue=st.session_state.queue)

    def _runner() -> None:
        # â˜…â˜…â˜… ä¿®æ­£: è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ â˜…â˜…â˜…
        try:
            asyncio.run(loop.run())
        except exceptiongroup.ExceptionGroup as eg:
            print("\n--- ERROR: ExceptionGroup caught in runner ---")
            for i, exc in enumerate(eg.exceptions):
                print(
                    f"  Sub-exception {i+1}/{len(eg.exceptions)}: {type(exc).__name__}"
                )
                print(f"  {exc}")
            print("---------------------------------------------\n")
        except Exception as e:
            print(f"\n--- ERROR: Unexpected exception in runner: {e} ---\n")

    thread = threading.Thread(target=_runner, daemon=True)
    thread.start()
    st.session_state.loop_thread = thread
    st.session_state.audio_loop = loop
    st.session_state.app_state = "running"


def _stop_chat() -> None:
    if st.session_state.app_state != "running":
        return
    st.session_state.audio_loop.stop()  # type: ignore
    st.session_state.app_state = "stopped"


with st.sidebar:
    st.header("Controls")
    st.button(
        "â–¶ï¸ Start Conversation",
        on_click=_start_chat,
        disabled=st.session_state.app_state == "running",
    )
    st.button(
        "â¹ï¸ Stop Conversation",
        on_click=_stop_chat,
        disabled=st.session_state.app_state != "running",
    )
    st.markdown("---")

if st.session_state.app_state == "running":
    status_placeholder.success("Conversation runningâ€¦ Speak into your microphone.")
else:
    status_placeholder.info("Click **Start Conversation** to begin.")

try:
    while True:
        chunk = st.session_state.queue.get_nowait()
        st.session_state.text_buffer += chunk
except Empty:
    pass

text_placeholder.markdown(st.session_state.text_buffer or "_No transcript yetâ€¦_")
